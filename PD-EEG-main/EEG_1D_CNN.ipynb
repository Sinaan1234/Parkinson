{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "This file is used for classification of emotion-based EEG signals from PD and HC using 1D Convolutional Neural Network (1D-CNN). The input to 1D-CNN are *Raw*, *CSP*, and *SPV* features. While *Raw* and *SPV* features are obtained using `matlab_files/eeg_csp_raw_run.m`, *SPV* features are obtained using `eeg_spectral.ipynb`. The detailed architecture, input and output dimensions are explained in the paper. The highlighted part in the following image indicate the pipeline of the current file.\n",
    "\n",
    "Note: The configurations, like hyperparameter values, present in this file are not the final configurations as reported in the paper. The present configurations are maybe mutated for additional experiments. However, results reported in the paper can be reproduced by plugging in the appropriate configurations as mentioned in the paper.\n",
    "\n",
    "\n",
    "![1D CNN pipeline associated with the current notebook](images/1dcnn.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_1612/3983391154.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msio\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mConv1D\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAveragePooling1D\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormalization\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBatchNormalization\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m  \u001b[1;32mimport\u001b[0m \u001b[0mEarlyStopping\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'keras'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "from keras.layers import Conv1D, AveragePooling1D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.callbacks  import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Activation, Dense, Flatten, Dropout\n",
    "from keras.utils import np_utils\n",
    "from keras.optimizers import SGD, Adam, RMSprop\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.callbacks  import EarlyStopping\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "#os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Path to the pre-processed features\n",
    "#dataPath = '../data/iir_feat_tensor_full_with_full_labels.mat'\n",
    "dataPath = '../data/spectral_feat_tensor_full_with_full_labels.mat'\n",
    "\n",
    "# Path to save features, results, etc.\n",
    "savePath = '../results/1D_CNN_Results/Spectral/'\n",
    "\n",
    "# Experiment name\n",
    "experiment = 'HVLV_Spectral_PD'\n",
    "\n",
    "filename = savePath+'CNN_1D_results_'+experiment+'.mat'\n",
    "plot_title = 'HV vs LV Classification for Spectral Features (PD)'\n",
    "\n",
    "\n",
    "# --- Model parameters ---\n",
    "\n",
    "nb_filters = [16, 32, 32, 64, 128]  # Number of filters for convolution\n",
    "kernel_size = 3\n",
    "pool_size = 2\n",
    "stride_size = 2\n",
    "padding = 'same'\n",
    "weight_decay = 0.000001\n",
    "dense_layer_neuron_num = 128\n",
    "epochs = 30\n",
    "momentum =0.8\n",
    "\n",
    "# Load data\n",
    "matContent = sio.loadmat(dataPath)\n",
    "features = matContent['pd_feat']\n",
    "labels = np.squeeze(matContent['pd_hvlv_labels'])\n",
    "#labels[labels < 0] = 0\n",
    "print(labels)\n",
    "#labels[labels == 6] = 0\n",
    "#labels = labels.astype(int)\n",
    "\n",
    "#df = pd.read_csv(dataPath, header = None)\n",
    "#features = df.iloc[1:,:-2].to_numpy()\n",
    "#labels = df.iloc[1:,-1].to_numpy() # last but one column for PD vs NC\n",
    "\n",
    "#dict_hvlv = {1:0, 2:1, 3:0, 4:0, 5:1, 6:0} #HVLV labels mapping dictionary\n",
    "#labels = labels.map(dict_hvlv).to_numpy()\n",
    "#labels[labels == 1] = 0\n",
    "#labels[labels == 2] = 1\n",
    "#labels[labels == 3] = 1\n",
    "#labels[labels == 4] = 1\n",
    "#labels[labels == 5] = 1\n",
    "#labels[labels == 6] = 1\n",
    "#labels[labels < 0]=0\n",
    "#labels[labels == 6]=0\n",
    "\n",
    "# randomise the sample sequence\n",
    "rand_order = np.arange(features.shape[0])\n",
    "np.random.shuffle(rand_order)\n",
    "features = features[rand_order,]\n",
    "labels = np.squeeze(labels[rand_order,])\n",
    "class_num = np.size(np.unique(labels))\n",
    "labels_categorical = np_utils.to_categorical(labels, class_num)\n",
    "del matContent\n",
    "\n",
    "print('Features :', features.shape)\n",
    "print('Labels :', labels_categorical.shape)\n",
    "print('Number of classes :', class_num)\n",
    "print('Unique labels:',np.unique(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Function to create, and compile Keras model\n",
    "def create_model(init_mode, activation, dropout_rate, optimizer, learn_rate):\n",
    "#def create_model(activation):\n",
    "  model = Sequential()\n",
    "  model.add(Conv1D(filters=nb_filters[0], kernel_size=kernel_size, padding=padding,\n",
    "                   activation=activation, input_shape=(X.shape[1],X.shape[2]), trainable=True))\n",
    "  model.add(AveragePooling1D(pool_size=pool_size, strides=stride_size, padding=padding))\n",
    "  model.add(Conv1D(filters=nb_filters[1], kernel_size=kernel_size, padding=padding,\n",
    "                   activation=activation, kernel_initializer=init_mode, trainable=True))\n",
    "  model.add(AveragePooling1D(pool_size=pool_size, strides=stride_size, padding=padding))\n",
    "  model.add(Conv1D(filters=nb_filters[2], kernel_size=kernel_size, padding=padding,\n",
    "                   activation=activation, kernel_initializer=init_mode, trainable=True))\n",
    "  model.add(AveragePooling1D(pool_size=pool_size, strides=stride_size, padding=padding))\n",
    "  # ####added by me#####\n",
    "  #model.add(Conv1D(filters=nb_filters[3], kernel_size=kernel_size, padding=padding, activation=activation,\n",
    "  #              kernel_initializer='he_normal'))\n",
    "  #model.add(AveragePooling1D(pool_size=pool_size, strides=stride_size, padding=padding))\n",
    "  #model.add(Conv1D(filters=nb_filters[4], kernel_size=kernel_size, padding=padding, activation=activation,\n",
    "  #              kernel_initializer='he_normal'))\n",
    "  #model.add(AveragePooling1D(pool_size=pool_size, strides=stride_size, padding=padding))\n",
    "  # ####added by me#####\n",
    "  model.add(Flatten())\n",
    "  model.add(BatchNormalization(epsilon=0.001))\n",
    "  model.add(Dense(dense_layer_neuron_num, kernel_initializer=init_mode, activation=activation))\n",
    "  model.add(Dropout(dropout_rate))\n",
    "  model.add(Dense(class_num))\n",
    "  model.add(Activation('softmax'))\n",
    "  model.summary()\n",
    "  #model.load_weights('Gender_notClean_HIweights.hdf5')\n",
    "  #earlyStopping = EarlyStopping(monitor='val_loss', patience=2, verbose=1, mode='auto')\n",
    "  if optimizer == 'SGD':\n",
    "    opt = SGD(learning_rate=learn_rate / 10 ** epochs, momentum = momentum, decay = weight_decay, nesterov = True)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "  elif optimizer == 'Adam':\n",
    "    opt = Adam(learning_rate=learn_rate)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "  elif optimizer == 'RMSprop':\n",
    "    opt = RMSprop(learning_rate=learn_rate, epsilon=1e-07)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "  return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../results/CNN_1D/CNN_1D_CSP/CNN_1D_results_HVLV_csp_PD.mat'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\io\\matlab\\mio.py\u001b[0m in \u001b[0;36m_open_file\u001b[1;34m(file_like, appendmat, mode)\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mIOError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../results/CNN_1D/CNN_1D_CSP/CNN_1D_results_HVLV_csp_PD.mat'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_1612/1701633052.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmat_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'../results/CNN_1D/CNN_1D_CSP/CNN_1D_results_HVLV_csp_PD.mat'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloadmat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmat_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mbest_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'best_params'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mdel\u001b[0m \u001b[0mmat_path\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbest_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\io\\matlab\\mio.py\u001b[0m in \u001b[0;36mloadmat\u001b[1;34m(file_name, mdict, appendmat, **kwargs)\u001b[0m\n\u001b[0;32m    222\u001b[0m     \"\"\"\n\u001b[0;32m    223\u001b[0m     \u001b[0mvariable_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'variable_names'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 224\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0m_open_file_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mappendmat\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    225\u001b[0m         \u001b[0mMR\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmat_reader_factory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    226\u001b[0m         \u001b[0mmatfile_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMR\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_variables\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvariable_names\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\contextlib.py\u001b[0m in \u001b[0;36m__enter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    117\u001b[0m         \u001b[1;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 119\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    120\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"generator didn't yield\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\io\\matlab\\mio.py\u001b[0m in \u001b[0;36m_open_file_context\u001b[1;34m(file_like, appendmat, mode)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m@\u001b[0m\u001b[0mcontextmanager\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_open_file_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mappendmat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m     \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopened\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mappendmat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[1;32myield\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\io\\matlab\\mio.py\u001b[0m in \u001b[0;36m_open_file\u001b[1;34m(file_like, appendmat, mode)\u001b[0m\n\u001b[0;32m     43\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mappendmat\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mfile_like\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'.mat'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m                 \u001b[0mfile_like\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;34m'.mat'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m             raise IOError(\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../results/CNN_1D/CNN_1D_CSP/CNN_1D_results_HVLV_csp_PD.mat'"
     ]
    }
   ],
   "source": [
    "mat_path = '../results/CNN_1D/CNN_1D_CSP/CNN_1D_results_HVLV_csp_PD.mat'\n",
    "params = sio.loadmat(mat_path)\n",
    "best_params = params['best_params']\n",
    "del mat_path\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_1612/1558183322.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Standardize\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mfeat_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;31m#features = np.reshape(features, (feat_shape[0], feat_shape[1]*feat_shape[2]))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#scaler = StandardScaler()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'features' is not defined"
     ]
    }
   ],
   "source": [
    "# Standardize\n",
    "\n",
    "feat_shape = features.shape\n",
    "#features = np.reshape(features, (feat_shape[0], feat_shape[1]*feat_shape[2]))\n",
    "#scaler = StandardScaler()\n",
    "#scaler.fit(features)\n",
    "#scaleFeatures = scaler.transform(features)\n",
    "features = np.reshape(features, (features.shape[0], 42, -1))\n",
    "\n",
    "X = features\n",
    "Y = labels_categorical\n",
    "tf.keras.backend.clear_session()\n",
    "estimator = create_model(init_mode='he_normal', learn_rate=0.0001, optimizer='Adam', activation='sigmoid', \n",
    "                         dropout_rate=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'KerasClassifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_1612/3259466621.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcnn_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKerasClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuild_fn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Call the classifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#batch_size = [16,32]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#epochs = [5,10,15]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#optimizer = ['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'KerasClassifier' is not defined"
     ]
    }
   ],
   "source": [
    "cnn_model = KerasClassifier(build_fn=create_model, verbose=1)  # Call the classifier\n",
    "\n",
    "#batch_size = [16,32]\n",
    "#epochs = [5,10,15]\n",
    "#optimizer = ['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']\n",
    "#init_mode = ['uniform', 'lecun_uniform', 'normal', 'zero', 'he_normal', 'he_uniform']\n",
    "#activation = ['softmax', 'softsign', 'relu', 'tanh', 'sigmoid', 'linear']\n",
    "#dropout_rate = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5]\n",
    "#learn_rate = [0.001, 0.01, 0.1, 0.2, 0.3]\n",
    "#momentum = [0.0, 0.2, 0.4, 0.6, 0.8, 0.9]\n",
    "#neurons = [1, 5, 10, 15, 20, 25, 30]\n",
    "\n",
    "learn_rate = [0.0001, 0.001, 0.01]\n",
    "optimizer = ['SGD', 'Adam','RMSprop']\n",
    "#momentum = [0.8,0.9]\n",
    "init_mode = ['he_normal','he_uniform']\n",
    "activation = ['relu','tanh']\n",
    "dropout_rate = [0.3,0.4,0.5]\n",
    "foldNum = 10\n",
    "\n",
    "p_grid = dict(init_mode=init_mode, dropout_rate=dropout_rate, activation=activation,\n",
    "              optimizer=optimizer, learn_rate=learn_rate)\n",
    "              #, momentum=momentum)\n",
    "grid = GridSearchCV(estimator=cnn_model, param_grid=p_grid,\n",
    "                    cv=foldNum, verbose=0)\n",
    "# Standerdize\n",
    "feat_shape = features.shape\n",
    "#features = np.reshape(features, (feat_shape[0], feat_shape[1]*feat_shape[2]))\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(features)\n",
    "scaleFeatures = scaler.transform(features)\n",
    "scaleFeatures = np.reshape(scaleFeatures, (features.shape[0], 640, 14))\n",
    "\n",
    "# Perform Grid Search\n",
    "print('Performing Gridsearch')\n",
    "X = scaleFeatures\n",
    "Y = labels_categorical\n",
    "grid_result = grid.fit(X,Y)\n",
    "best_params = grid_result.best_params_\n",
    "print('Best parameters:', best_params)\n",
    "'''\n",
    "tf.keras.backend.clear_session()\n",
    "estimator = create_model(init_mode=best_params.get('init_mode'), \n",
    "                         learn_rate=best_params.get('learn_rate'), \n",
    "                         optimizer=best_params.get('optimizer'), \n",
    "                         #momentum=best_params.get('momentum'), \n",
    "                         activation=best_params.get('activation'), \n",
    "                         dropout_rate=best_params.get('dropout_rate'))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'StratifiedKFold' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_1612/3652307553.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;31m#channels = features.shape[2] # number of channels 14\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;31m# Use Stratified K Fold to make sure that the train data and test data split distribution match.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[0mkfold\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mStratifiedKFold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;31m#features = np.reshape(features, (features.shape[0],640,14)) #reshaped to (None, 3, 14) for spectral\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'StratifiedKFold' is not defined"
     ]
    }
   ],
   "source": [
    "foldNum = 5\n",
    "conf_mat = np.zeros((2,2))\n",
    "#conf_mat = np.zeros((6,6))\n",
    "f = 0\n",
    "val_loss = []\n",
    "val_accuracy = []\n",
    "train_loss = []\n",
    "train_accuracy = []\n",
    "f1_MacroNet = np.zeros([foldNum,]) \n",
    "f1_weightedNet = np.zeros([foldNum,])\n",
    "precisionNet = np.zeros([foldNum,])\n",
    "recallNet = np.zeros([foldNum,])\n",
    "accNet = np.zeros([foldNum,])\n",
    "\n",
    "#channels = features.shape[2] # number of channels 14\n",
    "# Use Stratified K Fold to make sure that the train data and test data split distribution match.\n",
    "kfold = StratifiedKFold(n_splits=5, random_state=100, shuffle=True)\n",
    "\n",
    "#features = np.reshape(features, (features.shape[0],640,14)) #reshaped to (None, 3, 14) for spectral\n",
    "\n",
    "cm_list = []\n",
    "for train, test in kfold.split(features, labels):\n",
    "    trainingFeatures = features[train,:,:]\n",
    "    testFeatures = features[test,:,:]\n",
    "    train_shape = trainingFeatures.shape\n",
    "    test_shape = testFeatures.shape\n",
    "    \n",
    "    # Standerdize \n",
    "    #scaler = StandardScaler()\n",
    "    #trainingFeatures = np.reshape(trainingFeatures, [train_shape[0], train_shape[1]*train_shape[2]])\n",
    "    #testFeatures = np.reshape(testFeatures, [test_shape[0], test_shape[1]*test_shape[2]])\n",
    "    #scaler.fit(trainingFeatures)\n",
    "    #trainingFeatures = scaler.transform(trainingFeatures)\n",
    "    #trainingFeatures = np.reshape(trainingFeatures, [train_shape[0],train_shape[1],train_shape[2]])\n",
    "    #testFeatures = scaler.transform(testFeatures)\n",
    "    #testFeatures = np.reshape(testFeatures,[test_shape[0], test_shape[1], test_shape[2]])\n",
    "    tf.keras.backend.clear_session()\n",
    "    estimator = create_model(init_mode=best_params.get('init_mode'),\n",
    "                         learn_rate=best_params.get('learn_rate'),\n",
    "                         optimizer=best_params.get('optimizer'),\n",
    "                         #momentum=best_params.get('momentum'),\n",
    "                         activation=best_params.get('activation'),\n",
    "                         dropout_rate=best_params.get('dropout_rate'))\n",
    "\n",
    "    estimator.summary()\n",
    "    X_train, X_val, y_train, y_val = train_test_split(trainingFeatures, labels_categorical[train,:], test_size=0.1,\n",
    "                                                      random_state=100, stratify=labels_categorical[train,:])\n",
    "    #earlyStopping = EarlyStopping(monitor='val_loss', patience=3, verbose=1, mode='min')\n",
    "    dummy = estimator.fit(X_train, y_train, validation_data=(X_val, y_val), batch_size=32, epochs=epochs, \n",
    "                          verbose=2, validation_split=0.1)\n",
    "    \n",
    "    predicted_labelsNet = estimator.predict_classes(testFeatures, verbose=0)\n",
    "    cm = confusion_matrix(labels[test,], predicted_labelsNet, labels=[0,1])\n",
    "    #cm = confusion_matrix(labels[test,], predicted_labelsNet, labels=[1,2,3,4,5,0])\n",
    "    cm = cm/cm.sum(axis=1, keepdims=True)\n",
    "    #conf_mat = conf_mat+cm\n",
    "    cm_list.append(cm)\n",
    "\n",
    "    precisionNet[f] = precision_score(labels[test,], predicted_labelsNet, average='macro')\n",
    "    recallNet[f] = recall_score(labels[test,], predicted_labelsNet, average='macro')\n",
    "    f1_MacroNet[f] = f1_score(labels[test,], predicted_labelsNet, average='macro')\n",
    "    f1_weightedNet[f] = f1_score(labels[test,], predicted_labelsNet, average='weighted')\n",
    "    accNet[f] = accuracy_score(labels[test,], predicted_labelsNet)\n",
    "    print(experiment + '_CNN: Fold %d : f1_macroscore: %.4f' % (f + 1, f1_MacroNet[f]))\n",
    "    print(experiment + '_CNN: Fold %d : f1_weightedscore: %.4f' % (f + 1, f1_weightedNet[f]))\n",
    "    print(experiment + '_CNN: Fold %d : acc: %.4f' % (f + 1, accNet[f]))\n",
    "    f += 1\n",
    "    train_loss.append(dummy.history['loss'])\n",
    "    val_loss.append(dummy.history['val_loss'])\n",
    "    train_accuracy.append(dummy.history['accuracy'])\n",
    "    val_accuracy.append(dummy.history['val_accuracy'])\n",
    "\n",
    "#xc = range(1,epochs+1)\n",
    "tr_loss_df = pd.DataFrame(train_loss)\n",
    "tr_acc_df = pd.DataFrame(train_accuracy)\n",
    "val_loss_df = pd.DataFrame(val_loss)\n",
    "val_acc_df = pd.DataFrame(val_accuracy)\n",
    "\n",
    "train_loss_mlist = tr_loss_df.mean(axis=0).to_numpy()\n",
    "train_loss_slist = tr_loss_df.std(axis=0).to_numpy()\n",
    "train_acc_mlist = tr_acc_df.mean(axis=0).to_numpy() \n",
    "train_acc_slist = tr_acc_df.std(axis=0).to_numpy() \n",
    "val_loss_mlist = val_loss_df.mean(axis=0).to_numpy() \n",
    "val_loss_slist = val_loss_df.std(axis=0).to_numpy() \n",
    "val_acc_mlist = val_acc_df.mean(axis=0).to_numpy()\n",
    "val_acc_slist = val_acc_df.std(axis=0).to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Visualise results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_1612/2020567796.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0my1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_loss_mlist\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0me1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_loss_slist\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.subplot(1, 2, 1)\n",
    "\n",
    "y1 = train_loss_mlist\n",
    "e1 = train_loss_slist\n",
    "y2 = val_loss_mlist\n",
    "e2 = val_loss_slist\n",
    "x1 = range(1, len(train_loss_mlist) + 1)\n",
    "a1 = plt.plot(x1, y1, color='#089FFF', label='Training Loss')\n",
    "plt.fill_between(x1, y1 - e1, y1 + e1, alpha=0.3, facecolor='#089FFF', linewidth=4)\n",
    "a2 = plt.plot(x1, y2, color='#cc9106', label='Validation Loss')\n",
    "plt.fill_between(x1, y2 - e2, y2 + e2, alpha=0.3, facecolor='#cc9106', linewidth=4)\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "y3 = train_acc_mlist\n",
    "e3 = train_acc_slist\n",
    "y4 = val_acc_mlist\n",
    "e4 = val_acc_slist\n",
    "x2 = range(1, len(train_acc_mlist) + 1)\n",
    "a1 = plt.plot(x2, y3, color='#089FFF', label='Training Accuracy')\n",
    "plt.fill_between(x2, y3 - e3, y3 + e3, alpha=0.3, facecolor='#089FFF', linewidth=4)\n",
    "a2 = plt.plot(x2, y4, color='#cc9106', label='Validation Accuracy')\n",
    "plt.fill_between(x2, y4 - e4, y4 + e4, alpha=0.3, facecolor='#cc9106', linewidth=4)\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "#plt.savefig(filename[:-4]+'_loss_acc_curve'+'.png')\n",
    "plt.show()\n",
    "\n",
    "#conf_mat /= conf_mat.sum(axis=1, keepdims=True) #Normalised values in the CM\n",
    "conf_mat = np.mean(cm_list, axis=0)\n",
    "#fig, ax = plt.subplots(figsize=(10,8))\n",
    "ax = sns.heatmap(conf_mat, cmap='YlGnBu', annot=True, fmt='.4f', vmin=0, vmax=1, annot_kws={'fontsize': 12})\n",
    "ax.set_yticklabels(['NC', 'PD'], rotation=0)\n",
    "ax.set_xticklabels(['NC', 'PD'], rotation=0)\n",
    "#ax.set_yticklabels(['Sad', 'Happy', 'Fear', 'Disgust', 'Surprise', 'Anger'], rotation = 0)\n",
    "#ax.set_xticklabels(['Sad', 'Happy', 'Fear', 'Disgust', 'Surprise', 'Anger'], rotation = 0)\n",
    "\n",
    "ax.set_title(plot_title)\n",
    "ax.get_figure().savefig(filename[:-4] + '_conf_mat' + '.png')\n",
    "plt.show()\n",
    "\n",
    "print('Mean and std of F1 MACRO is %.4f +- %.4f' % (np.mean(f1_MacroNet), np.std(f1_MacroNet)))\n",
    "print('Mean and std of F1 WEIGHTED is %.4f +- %.4f' % (np.mean(f1_weightedNet), np.std(f1_weightedNet)))\n",
    "print('Mean and std of accuracy is %.4f +- %.4f' % (np.mean(accNet), np.std(accNet)))\n",
    "\n",
    "# Save results\n",
    "sio.savemat(filename, {'precisionNet': precisionNet, 'recallNet': recallNet, 'f1_MacroNet': f1_MacroNet,\n",
    "                       'f1_weightedNet': f1_weightedNet, 'accNet': accNet, 'conf_mat': conf_mat,\n",
    "                       'conf_mat_list': cm_list,\n",
    "                       'best_params': best_params, 'experiment': experiment, 'nb_filters': nb_filters,\n",
    "                       'kernel_size': kernel_size, 'pool_size': pool_size, 'stride_size': stride_size,\n",
    "                       'padding': padding,\n",
    "                       'weight_decay': weight_decay, 'dense_layer_neuron_num': dense_layer_neuron_num, 'epochs': epochs,\n",
    "                       'train_loss': train_loss, 'train_accuracy': train_accuracy, 'val_loss': val_loss,\n",
    "                       'val_accuracy': val_accuracy})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
